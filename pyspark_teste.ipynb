{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+XaMs8X1INJrKGp5npTaM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hLuyucdiv8pM"
      },
      "outputs": [],
      "source": [
        "# instalar as dependências\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "# tornar o pyspark \"importável\"\n",
        "import findspark\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')"
      ],
      "metadata": {
        "id": "dJ0-C8yhwO7S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgNXXlUkwQ5J",
        "outputId": "9e0172c8-d688-4577-da67-e91f83468680"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.3.0\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5 (from pyspark==3.3.0)\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764009 sha256=e574ebaecc22493192a4af66ff04303123b5dcc78a0a85204d4ca47fe411fbbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/9c/6c/d5200fcf351ffa39cbe09911e99703283624cd037df58070d9\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iniciar uma sessão local e importar dados do Airbnb\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkSession.builder.appName(\"teste\").getOrCreate()\n",
        "sc.conf.set('spark.sql.sources.partitionOverwriteMode', 'dynamic')\n",
        "\n",
        "!wget --quiet --show-progress http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2023-06-05/visualisations/listings.csv\n",
        "\n",
        "# carregar dados do Airbnb\n",
        "df = sc.read.csv(\"./listings.csv\", inferSchema=True, header=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDrlzJQ1wXWJ",
        "outputId": "1857c892-1ec8-477f-d314-f9c77b9918e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rlistings.csv.2        0%[                    ]       0  --.-KB/s               \rlistings.csv.2      100%[===================>]   1.43M  --.-KB/s    in 0.1s    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "# df2 = df.select(\"name\")\n",
        "# df2 = df2.withColumn(\"nome2\", upper(\"name\"))\n",
        "# # df2.show(truncate=False)\n",
        "\n",
        "# df2.createOrReplaceTempView(\"dataframe\")\n",
        "# resul = sc.sql(\"select * from dataframe where name like '%shared baths%'\")\n",
        "# resul.show(truncate=False)\n",
        "# print(f'quantidade: {resul.count()}')\n",
        "\n",
        "# df.createOrReplaceTempView('airbnb')\n",
        "df2 = df.filter(df.neighbourhood == 'Centrum-West')\n",
        "df2 = df2.withColumn(\"ano\", date_format(df.last_review, \"yyyy\"))\n",
        "df2 = df2.withColumn(\"mes\", date_format(df.last_review, \"MM\"))\n",
        "df2 = df2.withColumn(\"dia\", date_format(df.last_review, \"dd\"))\n",
        "df2.select(\"ano\",\"mes\", \"dia\").show()\n",
        "df2.write.parquet('airbnb_ano_mes_dia/', partitionBy=['ano', 'mes', 'dia'], mode='overwrite')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US-b7MGNwgIs",
        "outputId": "b78cdf3d-a35b-4f38-9da1-498a09b39786"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+\n",
            "| ano|mes|dia|\n",
            "+----+---+---+\n",
            "|2023| 05| 01|\n",
            "|2022| 06| 26|\n",
            "|2023| 06| 03|\n",
            "|2022| 10| 23|\n",
            "|2022| 12| 29|\n",
            "|2023| 05| 19|\n",
            "|2023| 06| 05|\n",
            "|2022| 10| 14|\n",
            "|2023| 06| 02|\n",
            "|2023| 05| 17|\n",
            "|2022| 12| 31|\n",
            "|2023| 05| 02|\n",
            "|2023| 05| 29|\n",
            "|2023| 04| 29|\n",
            "|2023| 05| 29|\n",
            "|2023| 05| 17|\n",
            "|2023| 05| 05|\n",
            "|2023| 06| 01|\n",
            "|2023| 05| 26|\n",
            "|2022| 06| 28|\n",
            "+----+---+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = sc.read.parquet('/content/airbnb_ano_mes_dia/ano=2023')\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRAGBTa-y2DQ",
        "outputId": "26b49690-9b0e-41dd-c9cc-05d7e95ae31e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- host_id: integer (nullable = true)\n",
            " |-- host_name: string (nullable = true)\n",
            " |-- neighbourhood_group: string (nullable = true)\n",
            " |-- neighbourhood: string (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- room_type: string (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- minimum_nights: integer (nullable = true)\n",
            " |-- number_of_reviews: integer (nullable = true)\n",
            " |-- last_review: timestamp (nullable = true)\n",
            " |-- reviews_per_month: double (nullable = true)\n",
            " |-- calculated_host_listings_count: integer (nullable = true)\n",
            " |-- availability_365: integer (nullable = true)\n",
            " |-- number_of_reviews_ltm: integer (nullable = true)\n",
            " |-- license: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}